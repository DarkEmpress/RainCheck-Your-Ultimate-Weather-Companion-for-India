{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the dataset\n",
    "df = pd.read_csv('IndianWeatherRepository.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove redundant attributes\n",
    "col_to_remove=['country','latitude','longitude','timezone','last_updated_epoch','temperature_celsius','wind_mph','wind_direction','pressure_in','precip_in','feels_like_celsius','visibility_miles','gust_mph','sunrise','sunset','moonrise','moonset','moon_phase','moon_illumination']\n",
    "df = df.drop(columns=col_to_remove)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#location names per state/ UT\n",
    "count=df.groupby('region')['location_name'].nunique()\n",
    "print(count)\n",
    "count.plot(kind='bar')\n",
    "plt.title('Number of Locations by Region')\n",
    "plt.xlabel('Region')\n",
    "plt.ylabel('Number of Locations')\n",
    "plt.show()\n",
    "#conclusion: UP has the most no. of regions\n",
    "#andaman has the readings for only one region\n",
    "\n",
    "#frequency of each location\n",
    "frequency = df['location_name'].value_counts()\n",
    "print(frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the rows whose region name is Andaman and Nicobar Islands\n",
    "condition=df['region']=='Andaman and Nicobar Islands'\n",
    "df = df[condition]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Andaman has only 70 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WEATHER TYPES IN ANDAMAN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#different weather names used\n",
    "distinct_values = df['condition_text'].unique().tolist()\n",
    "print(distinct_values)\n",
    "print(\"There are \"+str(len(distinct_values))+\" distinct weather types in the dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MISSING VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#percentage of missing values\n",
    "missing_values=df.isnull()\n",
    "miss_percent=(missing_values.sum()/len(df))*100\n",
    "missing_data=pd.DataFrame({'missing percent': miss_percent})\n",
    "print(missing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REMOVE DUPLICATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify and remove duplicated rows\n",
    "duplicated_rows=df.duplicated(keep=False)\n",
    "print(duplicated_rows)\n",
    "duplicate_data=df[duplicated_rows]\n",
    "print(duplicate_data)\n",
    "df=df.drop_duplicates(keep='first')\n",
    "print('number of rows: ',df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA TYPE OF EACH ROW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data type of each row\n",
    "data_types = df.dtypes\n",
    "print(data_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REMOVE TIME STAMP FROM DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_column = df['last_updated']\n",
    "modified_column = my_column.apply(lambda x: x[:-5])\n",
    "df['last_updated'] = modified_column\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_delete = ['location_name','air_quality_Carbon_Monoxide', 'air_quality_Ozone','air_quality_Nitrogen_dioxide','air_quality_Sulphur_dioxide','air_quality_PM2.5','air_quality_PM10','air_quality_us-epa-index','air_quality_gb-defra-index']\n",
    "df = df.drop(columns=columns_to_delete)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convertng all int 64 datatypes to float 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the int64 data to float64\n",
    "df['humidity'] = df['humidity'].astype('float64')\n",
    "df['wind_degree'] = df['wind_degree'].astype('float64')\n",
    "df['cloud'] = df['cloud'].astype('float64')\n",
    "\n",
    "data_types = df.dtypes\n",
    "print(data_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encoding condition text for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create an instance of LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder on the column and transform the values\n",
    "df['condition_text'] = encoder.fit_transform(df['condition_text'])\n",
    "df['condition_text'] = df['condition_text'].astype(int)\n",
    "\n",
    "# Access the encoded classes\n",
    "encoded_classes = encoder.classes_\n",
    "print(\"Encoded Classes:\", encoded_classes)\n",
    "\n",
    "# Decode the encoded values to get the original labels\n",
    "decoded_labels = encoder.inverse_transform(df['condition_text'])\n",
    "print(\"Decoded Labels:\", decoded_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inserting 7 days worth ofdata in one row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_text = df['condition_text']\n",
    "df=df.assign(condition_text1= df['condition_text'].shift(-1))\n",
    "df=df.assign(condition_text2= df['condition_text'].shift(-2))\n",
    "df=df.assign(condition_text3= df['condition_text'].shift(-3))\n",
    "df=df.assign(condition_text4= df['condition_text'].shift(-4))\n",
    "df=df.assign(condition_text5= df['condition_text'].shift(-5))\n",
    "df=df.assign(condition_text6= df['condition_text'].shift(-6))\n",
    "df=df.assign(condition_text7= df['condition_text'].shift(-7))\n",
    "\n",
    "condition_text = df['last_updated']\n",
    "df=df.assign(last_updated1= df['last_updated'].shift(-1))\n",
    "df=df.assign(last_updated2= df['last_updated'].shift(-2))\n",
    "df=df.assign(last_updated3= df['last_updated'].shift(-3))\n",
    "df=df.assign(last_updated4= df['last_updated'].shift(-4))\n",
    "df=df.assign(last_updated5= df['last_updated'].shift(-5))\n",
    "df=df.assign(last_updated6= df['last_updated'].shift(-6))\n",
    "df=df.assign(last_updated7= df['last_updated'].shift(-7))\n",
    "\n",
    "condition_text = df['temperature_fahrenheit']\n",
    "df=df.assign(temperature_fahrenheit1= df['temperature_fahrenheit'].shift(-1))\n",
    "df=df.assign(temperature_fahrenheit2= df['temperature_fahrenheit'].shift(-2))\n",
    "df=df.assign(temperature_fahrenheit3= df['temperature_fahrenheit'].shift(-3))\n",
    "df=df.assign(temperature_fahrenheit4= df['temperature_fahrenheit'].shift(-4))\n",
    "df=df.assign(temperature_fahrenheit5= df['temperature_fahrenheit'].shift(-5))\n",
    "df=df.assign(temperature_fahrenheit6= df['temperature_fahrenheit'].shift(-6))\n",
    "df=df.assign(temperature_fahrenheit7= df['temperature_fahrenheit'].shift(-7))\n",
    "\n",
    "condition_text = df['wind_kph']\n",
    "df=df.assign(wind_kph1= df['wind_kph'].shift(-1))\n",
    "df=df.assign(wind_kph2= df['wind_kph'].shift(-2))\n",
    "df=df.assign(wind_kph3= df['wind_kph'].shift(-3))\n",
    "df=df.assign(wind_kph4= df['wind_kph'].shift(-4))\n",
    "df=df.assign(wind_kph5= df['wind_kph'].shift(-5))\n",
    "df=df.assign(wind_kph6= df['wind_kph'].shift(-6))\n",
    "df=df.assign(wind_kph7= df['wind_kph'].shift(-7))\n",
    "\n",
    "condition_text = df['wind_degree']\n",
    "df=df.assign(wind_degree1= df['wind_degree'].shift(-1))\n",
    "df=df.assign(wind_degree2= df['wind_degree'].shift(-2))\n",
    "df=df.assign(wind_degree3= df['wind_degree'].shift(-3))\n",
    "df=df.assign(wind_degree4= df['wind_degree'].shift(-4))\n",
    "df=df.assign(wind_degree5= df['wind_degree'].shift(-5))\n",
    "df=df.assign(wind_degree6= df['wind_degree'].shift(-6))\n",
    "df=df.assign(wind_degree7= df['wind_degree'].shift(-7))\n",
    "\n",
    "condition_text = df['pressure_mb']\n",
    "df=df.assign(pressure_mb1= df['pressure_mb'].shift(-1))\n",
    "df=df.assign(pressure_mb2= df['pressure_mb'].shift(-2))\n",
    "df=df.assign(pressure_mb3= df['pressure_mb'].shift(-3))\n",
    "df=df.assign(pressure_mb4= df['pressure_mb'].shift(-4))\n",
    "df=df.assign(pressure_mb5= df['pressure_mb'].shift(-5))\n",
    "df=df.assign(pressure_mb6= df['pressure_mb'].shift(-6))\n",
    "df=df.assign(pressure_mb7= df['pressure_mb'].shift(-7))\n",
    "\n",
    "condition_text = df['precip_mm']\n",
    "df=df.assign(precip_mm1= df['precip_mm'].shift(-1))\n",
    "df=df.assign(precip_mm2= df['precip_mm'].shift(-2))\n",
    "df=df.assign(precip_mm3= df['precip_mm'].shift(-3))\n",
    "df=df.assign(precip_mm4= df['precip_mm'].shift(-4))\n",
    "df=df.assign(precip_mm5= df['precip_mm'].shift(-5))\n",
    "df=df.assign(precip_mm6= df['precip_mm'].shift(-6))\n",
    "df=df.assign(precip_mm7= df['precip_mm'].shift(-7))\n",
    "\n",
    "condition_text = df['humidity']\n",
    "df=df.assign(humidity1= df['humidity'].shift(-1))\n",
    "df=df.assign(humidity2= df['humidity'].shift(-2))\n",
    "df=df.assign(humidity3= df['humidity'].shift(-3))\n",
    "df=df.assign(humidity4= df['humidity'].shift(-4))\n",
    "df=df.assign(humidity5= df['humidity'].shift(-5))\n",
    "df=df.assign(humidity6= df['humidity'].shift(-6))\n",
    "df=df.assign(humidity7= df['humidity'].shift(-7))\n",
    "\n",
    "condition_text = df['cloud']\n",
    "df=df.assign(cloud1= df['cloud'].shift(-1))\n",
    "df=df.assign(cloud2= df['cloud'].shift(-2))\n",
    "df=df.assign(cloud3= df['cloud'].shift(-3))\n",
    "df=df.assign(cloud4= df['cloud'].shift(-4))\n",
    "df=df.assign(cloud5= df['cloud'].shift(-5))\n",
    "df=df.assign(cloud6= df['cloud'].shift(-6))\n",
    "df=df.assign(cloud7= df['cloud'].shift(-7))\n",
    "\n",
    "condition_text = df['visibility_km']\n",
    "df=df.assign(visibility_km1= df['visibility_km'].shift(-1))\n",
    "df=df.assign(visibility_km2= df['visibility_km'].shift(-2))\n",
    "df=df.assign(visibility_km3= df['visibility_km'].shift(-3))\n",
    "df=df.assign(visibility_km4= df['visibility_km'].shift(-4))\n",
    "df=df.assign(visibility_km5= df['visibility_km'].shift(-5))\n",
    "df=df.assign(visibility_km6= df['visibility_km'].shift(-6))\n",
    "df=df.assign(visibility_km7= df['visibility_km'].shift(-7))\n",
    "\n",
    "\n",
    "data= df[['region','last_updated','temperature_fahrenheit','wind_kph','wind_degree','pressure_mb','precip_mm','humidity','cloud','visibility_km','condition_text','last_updated1','temperature_fahrenheit1','wind_kph1','wind_degree1','pressure_mb1','precip_mm1','humidity1','cloud1','visibility_km1','condition_text1','last_updated2','temperature_fahrenheit2','wind_kph2','wind_degree2','pressure_mb2','precip_mm2','humidity2','cloud2','visibility_km2','condition_text2','last_updated3','temperature_fahrenheit3','wind_kph3','wind_degree3','pressure_mb3','precip_mm3','humidity3','cloud3','visibility_km3','condition_text3','last_updated4','temperature_fahrenheit4','wind_kph4','wind_degree4','pressure_mb4','precip_mm4','humidity4','cloud4','visibility_km4','condition_text4','last_updated5','temperature_fahrenheit5','wind_kph5','wind_degree5','pressure_mb5','precip_mm5','humidity5','cloud5','visibility_km5','condition_text5','last_updated6','temperature_fahrenheit6','wind_kph6','wind_degree6','pressure_mb6','precip_mm6','humidity6','cloud6','visibility_km6','condition_text6','last_updated7','temperature_fahrenheit7','wind_kph7','wind_degree7','pressure_mb7','precip_mm7','humidity7','cloud7','visibility_km7','condition_text7']]\n",
    "data=data.dropna()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since the accuracy has seen a significant increase we are going to stick with the current independent variables but due to the warning we might need to check for multicollinearity\n",
    "corr_matrix=data.corr()\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.heatmap(corr_matrix, cmap=\"YlGnBu\")\n",
    "plt.show()\n",
    "#cloud is strongly related to humidity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since the condition text can be predicted with 92% accuracy using the rows preceding it we can predict the weather of the upcoming days using the same columns for next day and so on. So we will predict the temperature, pressure, wind speen for the next 7 days and then use that to predict the weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first we will normalise all numerical values and see if it helps improve accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Select only the numerical columns\n",
    "numerical_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Create an instance of MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler on the numerical columns and transform the values\n",
    "data[numerical_columns] = scaler.fit_transform(data[numerical_columns])\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets see how the accuracy of condition_text changes with normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Load the dataset\n",
    "X = data.iloc[:, [2,3,4,5,6,7,8,9]].values\n",
    "y = data.iloc[:, 10].values\n",
    "accuracy=0\n",
    "max_accuracy=0\n",
    "rand_i=0\n",
    "rand_j=0\n",
    "for i in range(0,100):\n",
    "    for j in range(0,100):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i)\n",
    "        clf = tree.DecisionTreeClassifier(random_state=j)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        if accuracy > max_accuracy:\n",
    "            max_accuracy = accuracy\n",
    "            rand_i = i\n",
    "            rand_j = j\n",
    "print(\"Accuracy:\", max_accuracy*100,\"%\",\" \\nRandom state for splitting the training and data set: \",rand_i,\"\\nRandom state for decision tree classifier: \",rand_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are now going to approach the solution using DECISION TREE CLASSIFIER\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Load the dataset\n",
    "X = data.iloc[:, [2,3,4,5,6,7,8,9]].values\n",
    "y = data.iloc[:, 10].values\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Create a decision tree classifier\n",
    "clf = tree.DecisionTreeClassifier(random_state=18)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction using user input\n",
    "user_input = np.array([[80.6, 12.6, 134, 1009, 0, 84, 28, 10, ]])\n",
    "#user_input_normalized = np.concatenate((scaler.transform(user_input[:, :8]), user_input[:, 8:]), axis=1)\n",
    "prediction= clf.predict(user_input)\n",
    "print(\"Prediction:\", prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the model works. now we use today's temperature to predict tomorrow's temperature and so on for all the features and then use these predicted features to predict 7 day weather"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
