{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USING ARIMA MODEL TO PREDICT TIME SERIES DATA FORTHE NEXT 7 DAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the dataset\n",
    "df = pd.read_csv('IndianWeatherRepository.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove redundant attributes\n",
    "col_to_remove=['country','latitude','longitude','timezone','last_updated_epoch','temperature_celsius','wind_mph','wind_direction','pressure_in','precip_in','feels_like_celsius','feels_like_fahrenheit','visibility_miles','gust_mph','uv_index','gust_kph','sunrise','sunset','moonrise','moonset','moon_phase','moon_illumination','location_name','air_quality_Carbon_Monoxide', 'air_quality_Ozone','air_quality_Nitrogen_dioxide','air_quality_Sulphur_dioxide','air_quality_PM2.5','air_quality_PM10','air_quality_us-epa-index','air_quality_gb-defra-index']\n",
    "df = df.drop(columns=col_to_remove)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the rows whose region name is Andaman and Nicobar Islands\n",
    "condition=df['region']=='Andaman and Nicobar Islands'\n",
    "df = df[condition]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#different weather names used\n",
    "distinct_values = df['condition_text'].unique().tolist()\n",
    "print(distinct_values)\n",
    "print(\"There are \"+str(len(distinct_values))+\" distinct weather types in the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#percentage of missing values\n",
    "missing_values=df.isnull()\n",
    "miss_percent=(missing_values.sum()/len(df))*100\n",
    "missing_data=pd.DataFrame({'missing percent': miss_percent})\n",
    "print(missing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify and remove duplicated rows\n",
    "duplicated_rows=df.duplicated(keep=False)\n",
    "print(duplicated_rows)\n",
    "duplicate_data=df[duplicated_rows]\n",
    "print(duplicate_data)\n",
    "df=df.drop_duplicates(keep='first')\n",
    "print('number of rows: ',df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data type of each row\n",
    "data_types = df.dtypes\n",
    "print(data_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''my_column = df['last_updated']\n",
    "modified_column = my_column.apply(lambda x: x[:-5])\n",
    "df['last_updated'] = modified_column\n",
    "df\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the int64 data to float64\n",
    "df['humidity'] = df['humidity'].astype('float64')\n",
    "df['wind_degree'] = df['wind_degree'].astype('float64')\n",
    "df['cloud'] = df['cloud'].astype('float64')\n",
    "\n",
    "data_types = df.dtypes\n",
    "print(data_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ENCODING CONDITION TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create an instance of LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder on the column and transform the values\n",
    "df['condition_text'] = encoder.fit_transform(df['condition_text'])\n",
    "df['condition_text'] = df['condition_text'].astype(int)\n",
    "\n",
    "# Access the encoded classes\n",
    "encoded_classes = encoder.classes_\n",
    "#print(\"Encoded Classes:\", encoded_classes)\n",
    "\n",
    "# Decode the encoded values to get the original labels\n",
    "decoded_labels = encoder.inverse_transform(df['condition_text'])\n",
    "#print(\"Decoded Labels:\", decoded_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARIMA FOR NEXT 7 DAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Set the date column as the index\n",
    "df['last_updated'] = pd.to_datetime(df['last_updated'])\n",
    "df.set_index('last_updated', inplace=True)\n",
    "\n",
    "# Select the parameters for prediction\n",
    "parameters = ['temperature_fahrenheit', 'wind_kph', 'wind_degree', 'pressure_mb',\n",
    "              'precip_mm', 'humidity', 'cloud', 'visibility_km']\n",
    "\n",
    "# Create an empty DataFrame to store predictions\n",
    "predictions_df = pd.DataFrame()\n",
    "# Iterate over each parameter\n",
    "for param in parameters:\n",
    "    # Split the data into training and testing sets\n",
    "    train_data = df[:-7][param]\n",
    "    test_data = df[-7:][param]\n",
    "\n",
    "    # Fit an ARIMA model\n",
    "    model = ARIMA(train_data, order=(5, 2, 2))  # Adjust the order as needed\n",
    "    model_fit = model.fit()\n",
    "\n",
    "    # Make predictions for the next 7 days\n",
    "    predictions = model_fit.forecast(steps=7)\n",
    "\n",
    "    # Print the predictions\n",
    "    print(f\"Predictions for {param}:\")\n",
    "    print(predictions)\n",
    "    print()\n",
    "    predictions_df[param] = predictions\n",
    "\n",
    "# Print the predictions DataFrame\n",
    "print(predictions_df)\n",
    "\n",
    "# Calculate accuracy metrics\n",
    "mae = mean_absolute_error(test_data, predictions)\n",
    "mse = mean_squared_error(test_data, predictions)\n",
    "rmse = mean_squared_error(test_data, predictions, squared=False)\n",
    "\n",
    "# Print the accuracy metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NORMALISE BEFORE CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Select only the numerical columns\n",
    "numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Create an instance of MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler on the numerical columns and transform the values\n",
    "df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DECISION TREE CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are now going to approach the solution using DECISION TREE CLASSIFIER\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Load the dataset\n",
    "X = df.iloc[:, [1,3,4,5,6,7,8,9]].values\n",
    "y = df.iloc[:, 2].values\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Create a decision tree classifier\n",
    "clf = tree.DecisionTreeClassifier(random_state=18)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Select only the numerical columns\n",
    "numerical_columns = predictions_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Create an instance of MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler on the numerical columns and transform the values\n",
    "predictions_df[numerical_columns] = scaler.fit_transform(predictions_df[numerical_columns])\n",
    "pred=clf.predict(predictions_df)\n",
    "#print(pred)\n",
    "\n",
    "# Decode the encoded values to get the original labels\n",
    "decoded_labels = encoder.inverse_transform(pred)\n",
    "\n",
    "# Print the decoded labels\n",
    "print(\"Decoded Labels:\", decoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_7_rows = df.tail(7)\n",
    "#print(last_7_rows['condition_text'])\n",
    "# Decode the encoded values to get the original labels\n",
    "decoded_labels = encoder.inverse_transform(last_7_rows['condition_text'])\n",
    "\n",
    "# Print the decoded labels\n",
    "print(\"Decoded Labels:\", decoded_labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
